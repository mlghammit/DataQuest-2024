{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"fraudTest.csv\")\n",
    "df2 = pd.read_csv(\"fraudTrain.csv\")\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "new_column_names = [\n",
    "    \"transDate\",\n",
    "    \"creditCardNum\",\n",
    "    \"business\",\n",
    "    \"category\",\n",
    "    \"amount\",\n",
    "    \"firstName\",\n",
    "    \"lastName\",\n",
    "    \"gender\",\n",
    "    \"street\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"zip\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "    \"cityPop\",\n",
    "    \"job\",\n",
    "    \"dateOfBirth\",\n",
    "    \"transNum\",\n",
    "    \"unixTime\",\n",
    "    \"merchLatitude\",\n",
    "    \"merchLongitude\",\n",
    "    \"isFraud\",\n",
    "]\n",
    "\n",
    "df = df.rename(columns=dict(zip(df.columns, new_column_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_datatypes(df):\n",
    "    # Format dates\n",
    "    df[\"transDate\"] = pd.to_datetime(df[\"transDate\"])\n",
    "    df[\"dateOfBirth\"] = pd.to_datetime(df[\"dateOfBirth\"], format=\"%Y-%m-%d\")\n",
    "    df[\"unixTime\"] = pd.to_datetime(df[\"unixTime\"], unit=\"s\")\n",
    "\n",
    "    # Format categories\n",
    "    df[\"business\"] = df[\"business\"].astype(\"category\")\n",
    "    df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"city\"] = df[\"city\"].astype(\"category\")\n",
    "    df[\"state\"] = df[\"state\"].astype(\"category\")\n",
    "    df[\"job\"] = df[\"job\"].astype(\"category\")\n",
    "\n",
    "    # Format strings\n",
    "    df[\"creditCardNum\"] = df[\"creditCardNum\"].astype(str)\n",
    "    df[\"firstName\"] = df[\"firstName\"].astype(str)\n",
    "    df[\"lastName\"] = df[\"lastName\"].astype(str)\n",
    "    df[\"street\"] = df[\"street\"].astype(str)\n",
    "    df[\"zip\"] = df[\"zip\"].astype(str)\n",
    "    df[\"transNum\"] = df[\"transNum\"].astype(str)\n",
    "\n",
    "    # Format bool\n",
    "    df[\"isFraud\"] = df[\"isFraud\"].astype(bool)\n",
    "\n",
    "    # Fix UNIX time\n",
    "    df[\"transDate\"] = df[\"unixTime\"] + pd.DateOffset(years=7)\n",
    "    df.drop(columns=[\"unixTime\"], inplace=True)\n",
    "\n",
    "\n",
    "from vincenty import vincenty_inverse\n",
    "\n",
    "\n",
    "def distance_from_home(row):\n",
    "    coords_home = (row[\"longitude\"], row[\"latitude\"])\n",
    "    coords_purchase = (row[\"merchLongitude\"], row[\"merchLatitude\"])\n",
    "\n",
    "    return vincenty_inverse(coords_home, coords_purchase).km\n",
    "\n",
    "\n",
    "def calcuate_distances(df):\n",
    "    df[\"distance_customer_merchant\"] = df.apply(distance_from_home, axis=1)\n",
    "\n",
    "\n",
    "def calculate_fraudrates(df):\n",
    "    # encode city\n",
    "    grouped_transactions = df.groupby(\"city\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"city_fraudrate\"] = df[\"city\"].map(result_dict)\n",
    "    df.drop(columns=[\"city\"], inplace=True)\n",
    "\n",
    "    # encode job\n",
    "    grouped_transactions = df.groupby(\"job\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"job_fraudrate\"] = df[\"job\"].map(result_dict)\n",
    "    df.drop(columns=[\"job\"], inplace=True)\n",
    "\n",
    "\n",
    "def determine_history(df):\n",
    "    df[\"historyOfFraud\"] = df[\"creditCardNum\"].duplicated(keep=False) & df[\"isFraud\"]\n",
    "\n",
    "\n",
    "def process_dates(df):\n",
    "    df[\"trans_day\"] = df[\"transDate\"].dt.dayofyear\n",
    "    df[\"trans_weekday\"] = df[\"transDate\"].dt.weekday\n",
    "    df[\"trans_hour\"] = df[\"transDate\"].dt.hour\n",
    "    df[\"age_at_transaction\"] = df[\"transDate\"].dt.year - df[\"dateOfBirth\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    new_df = df.drop(\n",
    "        columns=[\n",
    "            \"creditCardNum\",\n",
    "            \"business\",\n",
    "            \"firstName\",\n",
    "            \"lastName\",\n",
    "            \"gender\",\n",
    "            \"street\",\n",
    "            \"zip\",\n",
    "            \"state\",\n",
    "            \"transNum\",\n",
    "            \"merchLatitude\",\n",
    "            \"merchLongitude\",\n",
    "            \"latitude\",\n",
    "            \"longitude\",\n",
    "            \"dateOfBirth\",\n",
    "            \"transDate\",\n",
    "        ]\n",
    "    )\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/nrpbxz756vv3_l8mp02k87k80000gn/T/ipykernel_82025/1054228429.py:47: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_transactions = df.groupby(\"city\")\n",
      "/var/folders/dy/nrpbxz756vv3_l8mp02k87k80000gn/T/ipykernel_82025/1054228429.py:57: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_transactions = df.groupby(\"job\")\n"
     ]
    }
   ],
   "source": [
    "def process_dataset(df):\n",
    "    new_df = df.copy()\n",
    "\n",
    "    process_datatypes(new_df)\n",
    "    calcuate_distances(new_df)\n",
    "    calculate_fraudrates(new_df)\n",
    "    determine_history(new_df)\n",
    "    process_dates(new_df)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "df_train = process_dataset(df)\n",
    "df_train = drop_columns(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode city\n",
    "grouped_transactions = df.groupby(\"city\")\n",
    "total_transactions = grouped_transactions.size()\n",
    "fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "city_result_dict = fraud_rate.to_dict()\n",
    "\n",
    "\n",
    "# encode job\n",
    "grouped_transactions = df.groupby(\"job\")\n",
    "total_transactions = grouped_transactions.size()\n",
    "fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "job_result_dict = fraud_rate.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"city_fraudrates.json\", \"w\") as file:\n",
    "    json.dump(city_result_dict, file)\n",
    "\n",
    "with open(\"job_fraudrates.json\", \"w\") as file:\n",
    "    json.dump(job_result_dict, file)\n",
    "\n",
    "with open(\"city_fraudrates.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "with open(\"job_fraudrates.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df[\"city_fraudrate\"] = df[\"city\"].map(result_dict)\n",
    "df.drop(columns=[\"city\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df):\n",
    "    df = pd.get_dummies(df, columns=[\"category\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train = encode_categorical(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9750623441396509\n",
      "Precision: 0.9490909090909091\n",
      "Recall: 0.9775280898876404\n",
      "F1 Score: 0.9630996309963098\n",
      "Confusion Matrix:\n",
      " [[521  14]\n",
      " [  6 261]]\n"
     ]
    }
   ],
   "source": [
    "# OLD MODEL\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_data = pd.read_pickle(\"model_data.pkl\")\n",
    "model_data.drop(columns=[\"state\"], inplace=True)\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X = model_data.drop(columns=[\"isFraud\"])\n",
    "Y = model_data[\"isFraud\"]\n",
    "X_rus, y_rus = rus.fit_resample(X, Y)\n",
    "y_rus.value_counts()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_rus, y_rus, test_size=0.2, random_state=42, stratify=y_rus\n",
    ")\n",
    "\n",
    "rtc = RandomForestClassifier(\n",
    "    max_features=0.4,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    criterion=\"gini\",\n",
    "    random_state=42,\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rtc.predict_proba(X_test)[:, 1] >= 0.479\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9997606704107651\n",
      "Precision: 1.0\n",
      "Recall: 0.937995337995338\n",
      "F1 Score: 0.9680057733942747\n",
      "Confusion Matrix:\n",
      " [[553574      0]\n",
      " [   133   2012]]\n"
     ]
    }
   ],
   "source": [
    "# NEW TEST SET\n",
    "\n",
    "test_set = df_train.drop(columns=[\"isFraud\"])\n",
    "y_true = df_train[\"isFraud\"]\n",
    "\n",
    "y_pred = rtc.predict_proba(test_set)[:, 1] >= 0.479\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
