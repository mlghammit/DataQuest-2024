{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### System\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "### Set seed\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "### Mains\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# ### Models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "### Ensemble Models:\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "### Dats Splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "### Pipelines\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline, make_pipeline \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # Sampling Methods\n",
    "# from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "### Metrics:\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vincenty import vincenty_inverse\n",
    "\n",
    "def distance_from_home(trans_row, cardholder_row):\n",
    "    coords_home = (cardholder_row[\"longitude\"], cardholder_row[\"latitude\"])\n",
    "    coords_purchase = (trans_row[\"merchLongitude\"], trans_row[\"merchLatitude\"])\n",
    "\n",
    "    return vincenty_inverse(coords_home, coords_purchase).km\n",
    "\n",
    "def process_dataset(df):\n",
    "    # Format dates\n",
    "    df[\"transDate\"] = pd.to_datetime(df[\"transDate\"])\n",
    "    df[\"dateOfBirth\"] = pd.to_datetime(df[\"dateOfBirth\"])\n",
    "\n",
    "    # Format categories\n",
    "    df[\"business\"] = df[\"business\"].astype(\"category\")\n",
    "    df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"city\"] = df[\"city\"].astype(\"category\")\n",
    "    df[\"state\"] = df[\"state\"].astype(\"category\")\n",
    "    df[\"job\"] = df[\"job\"].astype(\"category\")\n",
    "\n",
    "    # Format strings\n",
    "    df[\"creditCardNum\"] = df[\"creditCardNum\"].astype(str)\n",
    "    df[\"firstName\"] = df[\"firstName\"].astype(str)\n",
    "    df[\"lastName\"] = df[\"lastName\"].astype(str)\n",
    "    df[\"street\"] = df[\"street\"].astype(str)\n",
    "    df[\"zip\"] = df[\"zip\"].astype(str)\n",
    "    df[\"transNum\"] = df[\"transNum\"].astype(str)\n",
    "\n",
    "    # Format bool\n",
    "    df[\"isFraud\"] = df[\"isFraud\"].astype(bool)\n",
    "\n",
    "    df[\"distance_customer_merchant\"] = df.apply(\n",
    "        lambda row: distance_from_home(row, row), axis=1) \n",
    "    \n",
    "    \n",
    "    # encode city\n",
    "    grouped_transactions = df.groupby(\"city\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"city_fraudrate\"] = df[\"city\"].map(result_dict)\n",
    "\n",
    "    # encode job\n",
    "    grouped_transactions = df.groupby(\"job\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"job_fraudrate\"] = df[\"job\"].map(result_dict)\n",
    "\n",
    "    df.sort_values(by=['creditCardNum', 'transDate'], inplace=True)\n",
    "    df['numOfPrevFraudTxns'] = df.groupby('creditCardNum')['isFraud'].cumsum() - df['isFraud']\n",
    "    df['historyOfFraud'] = (df['numOfPrevFraudTxns'] > 0).astype(int)\n",
    "    \n",
    "    \n",
    "    df[df['historyOfFraud'] > 0].iloc[0]\n",
    "    df[\"transDate\"] = pd.to_datetime(df[\"transDate\"])\n",
    "    df[\"dateOfBirth\"] = pd.to_datetime(df[\"dateOfBirth\"])\n",
    "    df[\"trans_day\"] = df[\"transDate\"].dt.dayofyear\n",
    "    df[\"trans_weekday\"] = df[\"transDate\"].dt.weekday\n",
    "    df[\"trans_hour\"] = df[\"transDate\"].dt.hour\n",
    "    df[\"age_at_transaction\"] = df[\"transDate\"].dt.year - df[\"dateOfBirth\"].dt.year\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False) \n",
    "    categories = df[\"category\"].values.reshape(-1, 1)\n",
    "    categories_encoded = onehot_encoder.fit_transform(categories)\n",
    "    categories_encoded_df = pd.DataFrame(\n",
    "        categories_encoded, columns=onehot_encoder.get_feature_names_out([\"category\"]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, categories_encoded_df], axis=1)\n",
    "    \n",
    "    drop_columns=[\n",
    "        \"business\",\n",
    "        \"firstName\",\n",
    "        \"lastName\",\n",
    "        \"gender\",\n",
    "        \"street\",\n",
    "        \"zip\",\n",
    "        \"unixTime\",\n",
    "        \"creditCardNum\",\n",
    "        \"transNum\",\n",
    "        \"merchLatitude\",\n",
    "        \"merchLongitude\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"dateOfBirth\",\n",
    "        \"transDate\",\n",
    "        \"job\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"category\"\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns=drop_columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kayaba_attribution/.virtualenvs/ds/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"workspace-michael/train.csv\")\n",
    "df = process_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>cityPop</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>distance_customer_merchant</th>\n",
       "      <th>city_fraudrate</th>\n",
       "      <th>job_fraudrate</th>\n",
       "      <th>numOfPrevFraudTxns</th>\n",
       "      <th>historyOfFraud</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473.36</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>83.762096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.77</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>27.199041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.01</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>42.251942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.93</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>12.615215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.75</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>20.007615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  cityPop  isFraud  distance_customer_merchant  city_fraudrate  \\\n",
       "0  473.36     1504    False                   83.762096             0.0   \n",
       "1  142.77     1504    False                   27.199041             0.0   \n",
       "2   49.01     1504    False                   42.251942             0.0   \n",
       "3  116.93     1504    False                   12.615215             0.0   \n",
       "4   75.75     1504    False                   20.007615             0.0   \n",
       "\n",
       "   job_fraudrate  numOfPrevFraudTxns  historyOfFraud  trans_day  \\\n",
       "0       1.392111                   0               0        190   \n",
       "1       1.392111                   0               0        191   \n",
       "2       1.392111                   0               0        191   \n",
       "3       1.392111                   0               0        192   \n",
       "4       1.392111                   0               0        192   \n",
       "\n",
       "   trans_weekday  ...  category_grocery_pos  category_health_fitness  \\\n",
       "0              1  ...                   0.0                      0.0   \n",
       "1              2  ...                   0.0                      0.0   \n",
       "2              2  ...                   0.0                      0.0   \n",
       "3              3  ...                   1.0                      0.0   \n",
       "4              3  ...                   0.0                      0.0   \n",
       "\n",
       "   category_home  category_kids_pets  category_misc_net  category_misc_pos  \\\n",
       "0            0.0                 0.0                0.0                0.0   \n",
       "1            0.0                 0.0                0.0                0.0   \n",
       "2            0.0                 1.0                0.0                0.0   \n",
       "3            0.0                 0.0                0.0                0.0   \n",
       "4            1.0                 0.0                0.0                0.0   \n",
       "\n",
       "   category_personal_care  category_shopping_net  category_shopping_pos  \\\n",
       "0                     0.0                    0.0                    0.0   \n",
       "1                     0.0                    0.0                    1.0   \n",
       "2                     0.0                    0.0                    0.0   \n",
       "3                     0.0                    0.0                    0.0   \n",
       "4                     0.0                    0.0                    0.0   \n",
       "\n",
       "   category_travel  \n",
       "0              1.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "KNeighborsClassifier\n",
      "RandomForestClassifier\n",
      "DecisionTreeClassifier\n",
      "GradientBoostingClassifier\n",
      "Model: LogisticRegression\n",
      "--> Precision: 88.1%\n",
      "--> Recall: 60.04%\n",
      "--> F1: 70.94%\n",
      "----------------------------------------\n",
      "Model: KNeighborsClassifier\n",
      "--> Precision: 93.96%\n",
      "--> Recall: 60.74%\n",
      "--> F1: 73.72%\n",
      "----------------------------------------\n",
      "Model: RandomForestClassifier\n",
      "--> Precision: 97.27%\n",
      "--> Recall: 83.18%\n",
      "--> F1: 89.22%\n",
      "----------------------------------------\n",
      "Model: DecisionTreeClassifier\n",
      "--> Precision: 84.85%\n",
      "--> Recall: 82.83%\n",
      "--> F1: 83.37%\n",
      "----------------------------------------\n",
      "Model: GradientBoostingClassifier\n",
      "--> Precision: 91.89%\n",
      "--> Recall: 80.71%\n",
      "--> F1: 86.06%\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pipelines = {\n",
    "    \"LogisticRegression\": make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    \"KNeighborsClassifier\": make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
    "    \"RandomForestClassifier\": make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    \"DecisionTreeClassifier\": make_pipeline(StandardScaler(), DecisionTreeClassifier()),\n",
    "    \"GradientBoostingClassifier\": make_pipeline(\n",
    "        StandardScaler(), GradientBoostingClassifier()\n",
    "    ),\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"isFraud\"]),\n",
    "    df[\"isFraud\"],\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    print(algo)\n",
    "    model = pipeline.fit(X_train.values, y_train)\n",
    "    fit_models[algo] = model\n",
    "    \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for name, model in fit_models.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    for metric in [\"precision\", \"recall\", \"f1\"]:\n",
    "        scores = cross_val_score(model, X_test, y_test, cv=10, scoring=metric)\n",
    "        mean_score = round(scores.mean() * 100, 2)\n",
    "        print(f\"--> {metric.capitalize()}: {mean_score}%\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      2\u001b[0m     df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misFraud\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m      3\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misFraud\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      4\u001b[0m     test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      8\u001b[0m rtc \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m      9\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,\n\u001b[1;32m     10\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     16\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mrtc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rtc\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.479\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(y_test, y_pred))\n",
      "File \u001b[0;32m~/.virtualenvs/ds/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.virtualenvs/ds/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/ds/lib/python3.8/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/.virtualenvs/ds/lib/python3.8/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"isFraud\"]),\n",
    "    df[\"isFraud\"],\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "rtc = RandomForestClassifier(\n",
    "    max_features=0.4,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    criterion=\"gini\",\n",
    "    random_state=42,\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rtc.predict_proba(X_test)[:, 1] >= 0.479\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
