{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### System\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "### Set seed\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "### Mains\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "# ### Models:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "### Ensemble Models:\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "\n",
    "### Dats Splits \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "### Pipelines\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline, make_pipeline \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # Sampling Methods\n",
    "# from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "\n",
    "### Metrics:\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vincenty import vincenty_inverse\n",
    "\n",
    "def distance_from_home(trans_row, cardholder_row):\n",
    "    coords_home = (cardholder_row[\"longitude\"], cardholder_row[\"latitude\"])\n",
    "    coords_purchase = (trans_row[\"merchLongitude\"], trans_row[\"merchLatitude\"])\n",
    "\n",
    "    return vincenty_inverse(coords_home, coords_purchase).km\n",
    "\n",
    "def process_dataset(df):\n",
    "    # Format dates\n",
    "    df[\"transDate\"] = pd.to_datetime(df[\"transDate\"])\n",
    "    df[\"dateOfBirth\"] = pd.to_datetime(df[\"dateOfBirth\"])\n",
    "\n",
    "    # Format categories\n",
    "    df[\"business\"] = df[\"business\"].astype(\"category\")\n",
    "    df[\"category\"] = df[\"category\"].astype(\"category\")\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"city\"] = df[\"city\"].astype(\"category\")\n",
    "    df[\"state\"] = df[\"state\"].astype(\"category\")\n",
    "    df[\"job\"] = df[\"job\"].astype(\"category\")\n",
    "\n",
    "    # Format strings\n",
    "    df[\"creditCardNum\"] = df[\"creditCardNum\"].astype(str)\n",
    "    df[\"firstName\"] = df[\"firstName\"].astype(str)\n",
    "    df[\"lastName\"] = df[\"lastName\"].astype(str)\n",
    "    df[\"street\"] = df[\"street\"].astype(str)\n",
    "    df[\"zip\"] = df[\"zip\"].astype(str)\n",
    "    df[\"transNum\"] = df[\"transNum\"].astype(str)\n",
    "\n",
    "    # Format bool\n",
    "    df[\"isFraud\"] = df[\"isFraud\"].astype(bool)\n",
    "\n",
    "    df[\"distance_customer_merchant\"] = df.apply(\n",
    "        lambda row: distance_from_home(row, row), axis=1) \n",
    "    \n",
    "    \n",
    "    # encode city\n",
    "    grouped_transactions = df.groupby(\"city\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"city_fraudrate\"] = df[\"city\"].map(result_dict)\n",
    "\n",
    "    # encode job\n",
    "    grouped_transactions = df.groupby(\"job\")\n",
    "    total_transactions = grouped_transactions.size()\n",
    "    fraud_transactions = grouped_transactions[\"isFraud\"].sum()\n",
    "    fraud_rate = (fraud_transactions / total_transactions) * 100\n",
    "    result_dict = fraud_rate.to_dict()\n",
    "\n",
    "    df[\"job_fraudrate\"] = df[\"job\"].map(result_dict)\n",
    "\n",
    "    df.sort_values(by=['creditCardNum', 'transDate'], inplace=True)\n",
    "    df['numOfPrevFraudTxns'] = df.groupby('creditCardNum')['isFraud'].cumsum() - df['isFraud']\n",
    "    df['historyOfFraud'] = (df['numOfPrevFraudTxns'] > 0).astype(int)\n",
    "    \n",
    "    \n",
    "    df[df['historyOfFraud'] > 0].iloc[0]\n",
    "    df[\"transDate\"] = pd.to_datetime(df[\"transDate\"])\n",
    "    df[\"dateOfBirth\"] = pd.to_datetime(df[\"dateOfBirth\"])\n",
    "    df[\"trans_day\"] = df[\"transDate\"].dt.dayofyear\n",
    "    df[\"trans_weekday\"] = df[\"transDate\"].dt.weekday\n",
    "    df[\"trans_hour\"] = df[\"transDate\"].dt.hour\n",
    "    df[\"age_at_transaction\"] = df[\"transDate\"].dt.year - df[\"dateOfBirth\"].dt.year\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False) \n",
    "    categories = df[\"category\"].values.reshape(-1, 1)\n",
    "    categories_encoded = onehot_encoder.fit_transform(categories)\n",
    "    categories_encoded_df = pd.DataFrame(\n",
    "        categories_encoded, columns=onehot_encoder.get_feature_names_out([\"category\"]))\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = pd.concat([df, categories_encoded_df], axis=1)\n",
    "    \n",
    "    drop_columns=[\n",
    "        \"business\",\n",
    "        \"firstName\",\n",
    "        \"lastName\",\n",
    "        \"gender\",\n",
    "        \"street\",\n",
    "        \"zip\",\n",
    "        \"unixTime\",\n",
    "        \"creditCardNum\",\n",
    "        \"transNum\",\n",
    "        \"merchLatitude\",\n",
    "        \"merchLongitude\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"dateOfBirth\",\n",
    "        \"transDate\",\n",
    "        \"job\",\n",
    "        \"city\",\n",
    "        \"state\",\n",
    "        \"category\"\n",
    "    ]\n",
    "    \n",
    "    df = df.drop(columns=drop_columns)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kayaba_attribution/.virtualenvs/ds/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"workspace-michael/train.csv\")\n",
    "df = process_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>cityPop</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>distance_customer_merchant</th>\n",
       "      <th>city_fraudrate</th>\n",
       "      <th>job_fraudrate</th>\n",
       "      <th>numOfPrevFraudTxns</th>\n",
       "      <th>historyOfFraud</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>473.36</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>83.762096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142.77</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>27.199041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.01</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>42.251942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.93</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>12.615215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.75</td>\n",
       "      <td>1504</td>\n",
       "      <td>False</td>\n",
       "      <td>20.007615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.392111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount  cityPop  isFraud  distance_customer_merchant  city_fraudrate  \\\n",
       "0  473.36     1504    False                   83.762096             0.0   \n",
       "1  142.77     1504    False                   27.199041             0.0   \n",
       "2   49.01     1504    False                   42.251942             0.0   \n",
       "3  116.93     1504    False                   12.615215             0.0   \n",
       "4   75.75     1504    False                   20.007615             0.0   \n",
       "\n",
       "   job_fraudrate  numOfPrevFraudTxns  historyOfFraud  trans_day  \\\n",
       "0       1.392111                   0               0        190   \n",
       "1       1.392111                   0               0        191   \n",
       "2       1.392111                   0               0        191   \n",
       "3       1.392111                   0               0        192   \n",
       "4       1.392111                   0               0        192   \n",
       "\n",
       "   trans_weekday  ...  category_grocery_pos  category_health_fitness  \\\n",
       "0              1  ...                   0.0                      0.0   \n",
       "1              2  ...                   0.0                      0.0   \n",
       "2              2  ...                   0.0                      0.0   \n",
       "3              3  ...                   1.0                      0.0   \n",
       "4              3  ...                   0.0                      0.0   \n",
       "\n",
       "   category_home  category_kids_pets  category_misc_net  category_misc_pos  \\\n",
       "0            0.0                 0.0                0.0                0.0   \n",
       "1            0.0                 0.0                0.0                0.0   \n",
       "2            0.0                 1.0                0.0                0.0   \n",
       "3            0.0                 0.0                0.0                0.0   \n",
       "4            1.0                 0.0                0.0                0.0   \n",
       "\n",
       "   category_personal_care  category_shopping_net  category_shopping_pos  \\\n",
       "0                     0.0                    0.0                    0.0   \n",
       "1                     0.0                    0.0                    1.0   \n",
       "2                     0.0                    0.0                    0.0   \n",
       "3                     0.0                    0.0                    0.0   \n",
       "4                     0.0                    0.0                    0.0   \n",
       "\n",
       "   category_travel  \n",
       "0              1.0  \n",
       "1              0.0  \n",
       "2              0.0  \n",
       "3              0.0  \n",
       "4              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9989000412484532\n",
      "Precision: 0.9839357429718876\n",
      "Recall: 0.8718861209964412\n",
      "F1 Score: 0.9245283018867925\n",
      "Confusion Matrix:\n",
      " [[36080     4]\n",
      " [   36   245]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[\"isFraud\"]),\n",
    "    df[\"isFraud\"],\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "rtc = RandomForestClassifier(\n",
    "    max_features=0.4,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    criterion=\"gini\",\n",
    "    random_state=42,\n",
    "    n_estimators=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rtc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rtc.predict_proba(X_test)[:, 1] >= 0.479\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
